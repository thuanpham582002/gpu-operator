apiVersion: apps/v1
kind: DaemonSet
metadata:
  labels:
    app: nvidia-nvitop-exporter
  name: nvidia-nvitop-exporter
  namespace: "FILLED BY THE OPERATOR"
  annotations:
    openshift.io/scc: nvidia-nvitop-exporter
spec:
  selector:
    matchLabels:
      app: nvidia-nvitop-exporter
  template:
    metadata:
      labels:
        app: nvidia-nvitop-exporter
    spec:
      nodeSelector:
        nvidia.com/gpu.deploy.nvitop-exporter: "true"
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
      priorityClassName: system-node-critical
      serviceAccountName: nvidia-nvitop-exporter
      hostNetwork: true
      hostPID: true
      initContainers:
      - name: toolkit-validation
        image: "FILLED BY THE OPERATOR"
        command: ['sh', '-c']
        args: ["until [ -f /run/nvidia/validations/toolkit-ready ]; do echo waiting for nvidia container stack to be setup; sleep 5; done"]
        securityContext:
          privileged: true
        volumeMounts:
          - name: run-nvidia
            mountPath: "/run/nvidia"
            mountPropagation: HostToContainer
      containers:
      - image: "FILLED BY THE OPERATOR"
        name: nvidia-nvitop-exporter
        env:
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        args: ["--bind-address", "0.0.0.0", "--port", "8000"]
        ports:
        - name: "metrics"
          containerPort: 8000
        securityContext:
          privileged: true
        volumeMounts:
        - name: "pod-gpu-resources"
          readOnly: true
          mountPath: "/var/lib/kubelet/pod-resources"
        resources:
          limits:
            memory: 200Mi
          requests:
            cpu: 100m
            memory: 100Mi
      volumes:
      - name: "pod-gpu-resources"
        hostPath:
          path: "/var/lib/kubelet/pod-resources"
      - name: run-nvidia
        hostPath:
          path: /run/nvidia